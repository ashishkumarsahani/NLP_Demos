{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyORpIgeV8MluWRaEqBFNQwD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "48b5f553dc404b36b56cf291937eeb87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb2118e0fc764441ae1b1db5ada484ed",
              "IPY_MODEL_9c5305d772e04f1b88b32e93d73e6666",
              "IPY_MODEL_c446a3730b924ebfa610e34a3625c36b"
            ],
            "layout": "IPY_MODEL_0ce78f8d1c384a0d9544d1294bcd8fe9"
          }
        },
        "fb2118e0fc764441ae1b1db5ada484ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78a328cf00f34685829d3524a213f7ca",
            "placeholder": "​",
            "style": "IPY_MODEL_b2549c255d2c4abe9ee96104c4b2f304",
            "value": "100%"
          }
        },
        "9c5305d772e04f1b88b32e93d73e6666": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84c1eb1997db48b69630689e87d1481c",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b449c6c2de2c49bb9f029333d506ac19",
            "value": 2
          }
        },
        "c446a3730b924ebfa610e34a3625c36b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_176a98b972e7485b82252eddb4879deb",
            "placeholder": "​",
            "style": "IPY_MODEL_d8e5f737e6fc413c8a4f78cb3fd6880d",
            "value": " 2/2 [00:00&lt;00:00,  9.58it/s]"
          }
        },
        "0ce78f8d1c384a0d9544d1294bcd8fe9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78a328cf00f34685829d3524a213f7ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2549c255d2c4abe9ee96104c4b2f304": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84c1eb1997db48b69630689e87d1481c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b449c6c2de2c49bb9f029333d506ac19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "176a98b972e7485b82252eddb4879deb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8e5f737e6fc413c8a4f78cb3fd6880d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29ddafed0372426f83be0b2c070066dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_222281b800b24c77bb4f92ee3455c3eb",
              "IPY_MODEL_9480a49f7a7d4cfbbaf08cfc956b6950",
              "IPY_MODEL_025628ce1c974aacad232cbae91d796c"
            ],
            "layout": "IPY_MODEL_a2f0c6dda2af48b6bd1195fa4b1d1830"
          }
        },
        "222281b800b24c77bb4f92ee3455c3eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d93833c14cc47358c4cfe345e48fd2e",
            "placeholder": "​",
            "style": "IPY_MODEL_988dff9148704a78a7a78029c9b3ef23",
            "value": "100%"
          }
        },
        "9480a49f7a7d4cfbbaf08cfc956b6950": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_714a59e61a614c658ff68ec633ecd977",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4fa80f5aab664a2ca4cf30577ad20661",
            "value": 3
          }
        },
        "025628ce1c974aacad232cbae91d796c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_851dfb864acf494fb8ff159803e8b131",
            "placeholder": "​",
            "style": "IPY_MODEL_6c71a9d387f14070b1f20b9fe8f569be",
            "value": " 3/3 [00:00&lt;00:00, 19.42it/s]"
          }
        },
        "a2f0c6dda2af48b6bd1195fa4b1d1830": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d93833c14cc47358c4cfe345e48fd2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "988dff9148704a78a7a78029c9b3ef23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "714a59e61a614c658ff68ec633ecd977": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fa80f5aab664a2ca4cf30577ad20661": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "851dfb864acf494fb8ff159803e8b131": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c71a9d387f14070b1f20b9fe8f569be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6cdfad4d0e91407c93603691d26445be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2e0e7a16deff407799b5e2e97f4b6d9f",
              "IPY_MODEL_53f762fa2d62482198b2bc77c2debda8",
              "IPY_MODEL_828ef186271b40bd81b183b1e62b2d24"
            ],
            "layout": "IPY_MODEL_7deb0b28970945bd8f2c99f02fb52b0f"
          }
        },
        "2e0e7a16deff407799b5e2e97f4b6d9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dad41ab1f884490d949f24f26fd7b93d",
            "placeholder": "​",
            "style": "IPY_MODEL_8a1666873b884a04b22ea9df28c106ac",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "53f762fa2d62482198b2bc77c2debda8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad22b05949b445f6b62cebbca807686e",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45b8794eac404c4e9abf96b9a05b5b1e",
            "value": 3
          }
        },
        "828ef186271b40bd81b183b1e62b2d24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3593aeb4ad724034b6d3a6de90362afd",
            "placeholder": "​",
            "style": "IPY_MODEL_24e823eb352a47d893f7db8bf3af2b0d",
            "value": " 3/3 [00:08&lt;00:00,  2.80s/it]"
          }
        },
        "7deb0b28970945bd8f2c99f02fb52b0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dad41ab1f884490d949f24f26fd7b93d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a1666873b884a04b22ea9df28c106ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad22b05949b445f6b62cebbca807686e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45b8794eac404c4e9abf96b9a05b5b1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3593aeb4ad724034b6d3a6de90362afd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24e823eb352a47d893f7db8bf3af2b0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashishkumarsahani/NLP_Demos/blob/main/RAG_using_LLAMA2_and_Deployment_on_Streamlit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3h0Pw36UCHW_",
        "outputId": "4592137e-29c3-47ab-9b3b-fadfc202e23d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: pinecone-client in /usr/local/lib/python3.10/dist-packages (4.1.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.20.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.31.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.5)\n",
            "Requirement already satisfied: xformers in /usr/local/lib/python3.10/dist-packages (0.0.26.post1)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.43.1)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.2.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.10/dist-packages (1.24.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.23.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2024.2.2)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (0.0.7)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (4.11.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone-client) (2.0.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.7)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.77)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.16)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n",
            "Collecting torch\n",
            "  Using cached torch-2.3.0-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Collecting triton==2.3.0 (from torch)\n",
            "  Using cached triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.5.14)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: PyMuPDFb==1.24.3 in /usr/local/lib/python3.10/dist-packages (from PyMuPDF) (1.24.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.7->langchain) (1.33)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.7->langchain) (3.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Installing collected packages: triton, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.3.1\n",
            "    Uninstalling triton-2.3.1:\n",
            "      Successfully uninstalled triton-2.3.1\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.3.1\n",
            "    Uninstalling torch-2.3.1:\n",
            "      Successfully uninstalled torch-2.3.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 2.3.0 which is incompatible.\n",
            "torchtext 0.17.1 requires torch==2.2.1, but you have torch 2.3.0 which is incompatible.\n",
            "torchvision 0.15.2 requires torch==2.0.1, but you have torch 2.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.3.0 triton-2.3.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install --upgrade \\\n",
        "  sentence-transformers \\\n",
        "  pinecone-client \\\n",
        "  datasets \\\n",
        "  accelerate \\\n",
        "  einops \\\n",
        "  langchain \\\n",
        "  xformers \\\n",
        "  bitsandbytes\\\n",
        "  langchain-community \\\n",
        "  torch \\\n",
        "  transformers \\\n",
        "  PyMuPDF"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import cuda\n",
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "embed_model_id = 'sentence-transformers/all-MiniLM-L6-v2'\n",
        "\n",
        "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
        "\n",
        "embed_model = HuggingFaceEmbeddings(\n",
        "    model_name=embed_model_id,\n",
        "    model_kwargs={'device': device},\n",
        "    encode_kwargs={'device': device, 'batch_size': 32}\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Bsxfd1_CKkz",
        "outputId": "0b00e908-b79d-49cc-807f-e09b675c8eaa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use the embedding model to create document embeddings like so:"
      ],
      "metadata": {
        "id": "vCrJs1vgIekp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building the Vector Index**\n",
        "We now need to use the embedding pipeline to build our embeddings and store them in a Pinecone vector index. To begin we'll initialize our index, for this we'll need a free Pinecone API key."
      ],
      "metadata": {
        "id": "ioXLV-d2IY9S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we setup our index specification, this allows us to define the cloud provider and region where we want to deploy our index."
      ],
      "metadata": {
        "id": "-LPBfo4cJwvU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we initialize the index."
      ],
      "metadata": {
        "id": "KDDo5fMNJ6Cf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With our index and embedding process ready we can move onto the indexing process itself. For that, we'll need a dataset. We will use a set of Arxiv papers related to (and including) the Llama 2 research paper."
      ],
      "metadata": {
        "id": "BrBLloLxLzID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "import os\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def read_pdf(file_path):\n",
        "    doc = fitz.open(file_path)\n",
        "    text = \"\"\n",
        "    for page_num in range(len(doc)):\n",
        "        page = doc.load_page(page_num)\n",
        "        text += page.get_text()\n",
        "    return text\n",
        "\n",
        "def chunk_text(text, chunk_size=1000):\n",
        "    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
        "\n",
        "# Directory containing PDFs\n",
        "pdf_dir = 'PDFStore'\n",
        "pdf_files = [os.path.join(pdf_dir, f) for f in os.listdir(pdf_dir) if f.endswith('.pdf')]\n",
        "\n",
        "data = []\n",
        "\n",
        "for pdf_file in tqdm(pdf_files):\n",
        "    text = read_pdf(pdf_file)\n",
        "    chunks = chunk_text(text)\n",
        "    for chunk_id, chunk in enumerate(chunks):\n",
        "        data.append({\n",
        "            'source': pdf_file,\n",
        "            'chunk_id': chunk_id,\n",
        "            'chunk': chunk\n",
        "        })\n",
        "\n",
        "data_df = pd.DataFrame(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "48b5f553dc404b36b56cf291937eeb87",
            "fb2118e0fc764441ae1b1db5ada484ed",
            "9c5305d772e04f1b88b32e93d73e6666",
            "c446a3730b924ebfa610e34a3625c36b",
            "0ce78f8d1c384a0d9544d1294bcd8fe9",
            "78a328cf00f34685829d3524a213f7ca",
            "b2549c255d2c4abe9ee96104c4b2f304",
            "84c1eb1997db48b69630689e87d1481c",
            "b449c6c2de2c49bb9f029333d506ac19",
            "176a98b972e7485b82252eddb4879deb",
            "d8e5f737e6fc413c8a4f78cb3fd6880d"
          ]
        },
        "id": "VnYLeJaKdz2m",
        "outputId": "1e040b06-d76d-4a59-d2c0-be037f2820eb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48b5f553dc404b36b56cf291937eeb87"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Assuming embed_model is your embedding model\n",
        "# and you have a method embed_model.embed_documents to get embeddings\n",
        "\n",
        "# Directory to save the embeddings\n",
        "os.makedirs('embeddings', exist_ok=True)\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "all_vectors = []\n",
        "\n",
        "for i in tqdm(range(0, len(data_df), batch_size)):\n",
        "    i_end = min(len(data_df), i + batch_size)\n",
        "    batch = data_df.iloc[i:i_end]\n",
        "    ids = [f\"{x['source']}-{x['chunk_id']}\" for _, x in batch.iterrows()]\n",
        "    texts = [x['chunk'] for _, x in batch.iterrows()]\n",
        "    embeds = embed_model.embed_documents(texts)\n",
        "\n",
        "    metadata = [\n",
        "        {'text': x['chunk'],\n",
        "         'source': x['source']} for _, x in batch.iterrows()\n",
        "    ]\n",
        "\n",
        "    for idx, embed, meta in zip(ids, embeds, metadata):\n",
        "        vector_data = {\n",
        "            'id': idx,\n",
        "            'embedding': embed,\n",
        "            'metadata': meta\n",
        "        }\n",
        "        all_vectors.append(vector_data)\n",
        "\n",
        "# Save all vectors to a pickle file\n",
        "with open('embeddings/vectors.pkl', 'wb') as f:\n",
        "    pickle.dump(all_vectors, f)\n",
        "\n",
        "print(\"Vectors have been saved locally.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "29ddafed0372426f83be0b2c070066dc",
            "222281b800b24c77bb4f92ee3455c3eb",
            "9480a49f7a7d4cfbbaf08cfc956b6950",
            "025628ce1c974aacad232cbae91d796c",
            "a2f0c6dda2af48b6bd1195fa4b1d1830",
            "3d93833c14cc47358c4cfe345e48fd2e",
            "988dff9148704a78a7a78029c9b3ef23",
            "714a59e61a614c658ff68ec633ecd977",
            "4fa80f5aab664a2ca4cf30577ad20661",
            "851dfb864acf494fb8ff159803e8b131",
            "6c71a9d387f14070b1f20b9fe8f569be"
          ]
        },
        "id": "NDBKVhowewcQ",
        "outputId": "341590d3-b295-4964-930e-972e37cc3209"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "29ddafed0372426f83be0b2c070066dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vectors have been saved locally.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_vectors[0]['id']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9CRUjDRJlUu4",
        "outputId": "3ab3bca9-2354-4f23-e4e0-b8075824a298"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'PDFStore/AARMED_Ventilator_Paper (1).pdf-0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_vectors[0]['embedding']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWSzaebwllRr",
        "outputId": "14af8038-08b6-4480-db88-4bea418bc00f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.005052613094449043,\n",
              " 0.03144381195306778,\n",
              " -0.03725692629814148,\n",
              " 0.022986436262726784,\n",
              " 0.044998981058597565,\n",
              " -0.07513134926557541,\n",
              " -0.013103531673550606,\n",
              " 0.11042957007884979,\n",
              " 0.03447945415973663,\n",
              " 0.014979658648371696,\n",
              " -0.03177201375365257,\n",
              " 0.032891470938920975,\n",
              " 0.09203609079122543,\n",
              " 0.09892263263463974,\n",
              " -0.07650760561227798,\n",
              " 0.02247806079685688,\n",
              " 0.04953918978571892,\n",
              " -0.025898050516843796,\n",
              " -0.060094255954027176,\n",
              " -0.030847813934087753,\n",
              " 0.0206847433000803,\n",
              " 0.08052218705415726,\n",
              " -0.010270497761666775,\n",
              " 0.03184668347239494,\n",
              " -0.07663623988628387,\n",
              " -0.04970858618617058,\n",
              " -0.05985566973686218,\n",
              " -0.0034310612827539444,\n",
              " -0.0013729274505749345,\n",
              " -0.004418091382831335,\n",
              " 0.021554183214902878,\n",
              " -0.014903075061738491,\n",
              " -0.014176206663250923,\n",
              " -0.0327991284430027,\n",
              " -0.03002236783504486,\n",
              " -0.03403373435139656,\n",
              " -0.01081168930977583,\n",
              " 0.054659947752952576,\n",
              " -0.12469235807657242,\n",
              " -0.024489223957061768,\n",
              " -0.018754536285996437,\n",
              " 0.00110986630897969,\n",
              " 0.04269465431571007,\n",
              " -0.008432216010987759,\n",
              " 0.06055694818496704,\n",
              " 0.0739060640335083,\n",
              " -0.08714550733566284,\n",
              " -0.0014596529072150588,\n",
              " 0.02540387026965618,\n",
              " 0.040823329240083694,\n",
              " -0.05031486600637436,\n",
              " -0.041599731892347336,\n",
              " 0.012344200164079666,\n",
              " 0.04527256637811661,\n",
              " -0.014923859387636185,\n",
              " 0.010228040628135204,\n",
              " -0.08979441225528717,\n",
              " -0.12190297245979309,\n",
              " -0.028588032349944115,\n",
              " -0.031154325231909752,\n",
              " 0.0330406092107296,\n",
              " 0.03950586915016174,\n",
              " 0.03712475299835205,\n",
              " 0.022065963596105576,\n",
              " -0.016928045079112053,\n",
              " -0.03149842098355293,\n",
              " 0.02044166438281536,\n",
              " -0.04117554798722267,\n",
              " 0.009188738651573658,\n",
              " 0.022756388410925865,\n",
              " -0.026353444904088974,\n",
              " -0.07695025950670242,\n",
              " 0.006921433378010988,\n",
              " 0.02988847903907299,\n",
              " 0.03666112944483757,\n",
              " 0.050991423428058624,\n",
              " 0.03798937052488327,\n",
              " -0.039675526320934296,\n",
              " 0.06226862594485283,\n",
              " 0.1144595816731453,\n",
              " -0.0062071820721030235,\n",
              " -0.02037177048623562,\n",
              " 0.009212988428771496,\n",
              " -0.037838201969861984,\n",
              " -0.01608983613550663,\n",
              " -0.009334960952401161,\n",
              " 0.061177123337984085,\n",
              " -0.060973163694143295,\n",
              " -0.051790859550237656,\n",
              " -0.00034155481262132525,\n",
              " 0.04471506550908089,\n",
              " 0.03254592791199684,\n",
              " 0.0021042663138359785,\n",
              " 0.027023272588849068,\n",
              " 0.04897371679544449,\n",
              " -0.042477671056985855,\n",
              " -0.0030005578882992268,\n",
              " 0.08877971023321152,\n",
              " -0.05032700300216675,\n",
              " -0.026323560625314713,\n",
              " -0.0677703395485878,\n",
              " 0.036524347960948944,\n",
              " 0.02524067461490631,\n",
              " 0.01866772212088108,\n",
              " -0.03759381175041199,\n",
              " -0.11954932659864426,\n",
              " 0.08647569268941879,\n",
              " -0.030820973217487335,\n",
              " 0.04807397350668907,\n",
              " 0.013839277438819408,\n",
              " 0.006272281054407358,\n",
              " 0.077953040599823,\n",
              " 0.01916109398007393,\n",
              " -0.033365096896886826,\n",
              " 0.02809235267341137,\n",
              " 0.1148836761713028,\n",
              " -0.005488571245223284,\n",
              " 0.028707006946206093,\n",
              " 0.016388434916734695,\n",
              " 0.04044817388057709,\n",
              " -0.03289568051695824,\n",
              " -0.044006723910570145,\n",
              " -0.009691305458545685,\n",
              " -0.08514441549777985,\n",
              " 0.060743968933820724,\n",
              " 0.013785192742943764,\n",
              " -0.05864362791180611,\n",
              " 7.753398372866601e-33,\n",
              " -0.056349024176597595,\n",
              " -0.019008664414286613,\n",
              " 0.061809610575437546,\n",
              " 0.06562156230211258,\n",
              " -0.08013195544481277,\n",
              " -0.033292096108198166,\n",
              " -0.0024220296181738377,\n",
              " -0.058480154722929,\n",
              " 0.06886352598667145,\n",
              " 0.030712705105543137,\n",
              " -0.07734867930412292,\n",
              " -0.00211264006793499,\n",
              " -0.03139274939894676,\n",
              " 0.037718765437603,\n",
              " 0.0026544982101768255,\n",
              " -0.07075504958629608,\n",
              " -0.045132555067539215,\n",
              " -0.051444269716739655,\n",
              " -0.07444997876882553,\n",
              " 0.008721229620277882,\n",
              " -0.01734432391822338,\n",
              " -0.07055609673261642,\n",
              " 0.05064132437109947,\n",
              " -0.02020816132426262,\n",
              " 0.048659179359674454,\n",
              " -0.04274753853678703,\n",
              " -0.016655389219522476,\n",
              " -0.029460763558745384,\n",
              " -0.0076852841302752495,\n",
              " 0.03839033469557762,\n",
              " -0.0032303794287145138,\n",
              " 0.010475211776793003,\n",
              " -0.03260118141770363,\n",
              " 1.6275573216262273e-05,\n",
              " -0.13801954686641693,\n",
              " -0.038670897483825684,\n",
              " -0.09704479575157166,\n",
              " -0.00357624189928174,\n",
              " -0.02261039800941944,\n",
              " -0.019269118085503578,\n",
              " -0.02068101428449154,\n",
              " 0.018565481528639793,\n",
              " -0.022509444504976273,\n",
              " -0.008397267200052738,\n",
              " 0.07718905806541443,\n",
              " -0.06210089474916458,\n",
              " -0.0559682659804821,\n",
              " 0.09089474380016327,\n",
              " -0.045679833739995956,\n",
              " -0.0533294752240181,\n",
              " -0.004559990484267473,\n",
              " 0.06139541044831276,\n",
              " 0.023905888199806213,\n",
              " -0.020919345319271088,\n",
              " -0.0007632842171005905,\n",
              " -0.008164487779140472,\n",
              " 0.061520837247371674,\n",
              " -0.04330858588218689,\n",
              " 0.02903151698410511,\n",
              " 0.06748434901237488,\n",
              " -0.14221830666065216,\n",
              " 0.06291841715574265,\n",
              " -0.03706757351756096,\n",
              " 0.020863531157374382,\n",
              " 0.008132101967930794,\n",
              " 0.06095201522111893,\n",
              " 0.03779371827840805,\n",
              " -0.04435501620173454,\n",
              " 0.014323349110782146,\n",
              " 0.028067179024219513,\n",
              " 0.035060007125139236,\n",
              " -0.06051066517829895,\n",
              " -0.013301237486302853,\n",
              " -0.025558752939105034,\n",
              " -0.006234963424503803,\n",
              " -0.013166440650820732,\n",
              " 0.08464888483285904,\n",
              " 0.10114452987909317,\n",
              " -0.05296635627746582,\n",
              " -0.11778287589550018,\n",
              " 0.05629690736532211,\n",
              " 0.06400444358587265,\n",
              " 0.06897463649511337,\n",
              " 0.060221534222364426,\n",
              " -0.035817377269268036,\n",
              " -0.09700198471546173,\n",
              " -0.02823144569993019,\n",
              " -0.02875533141195774,\n",
              " -0.04815175011754036,\n",
              " -0.03675861656665802,\n",
              " 0.021824819967150688,\n",
              " 0.05254000425338745,\n",
              " 0.02208832837641239,\n",
              " 0.04667593911290169,\n",
              " -0.018652502447366714,\n",
              " -7.853384452979606e-33,\n",
              " 0.03309425339102745,\n",
              " 0.015496999956667423,\n",
              " 0.047844983637332916,\n",
              " 0.02355753630399704,\n",
              " 0.0881560891866684,\n",
              " 0.05826789140701294,\n",
              " 0.08251553028821945,\n",
              " -0.06007767096161842,\n",
              " 0.04392616078257561,\n",
              " -0.08454816788434982,\n",
              " -0.020195025950670242,\n",
              " -0.0019457616144791245,\n",
              " -0.012618906795978546,\n",
              " 0.05399549379944801,\n",
              " 0.09789852797985077,\n",
              " 0.10770822316408157,\n",
              " -0.03403446078300476,\n",
              " -0.09906144440174103,\n",
              " -0.04225260764360428,\n",
              " 0.033626630902290344,\n",
              " 0.015328106470406055,\n",
              " 0.08451627194881439,\n",
              " -0.0011946940794587135,\n",
              " 0.02464260347187519,\n",
              " -0.07493475079536438,\n",
              " 0.06734366714954376,\n",
              " -0.0053970348089933395,\n",
              " 0.008793802931904793,\n",
              " 0.04777845740318298,\n",
              " -0.05336179584264755,\n",
              " -0.019543269649147987,\n",
              " -0.015617997385561466,\n",
              " 0.014967176131904125,\n",
              " 0.08635254949331284,\n",
              " -0.017842618748545647,\n",
              " -0.03020382672548294,\n",
              " 0.024972878396511078,\n",
              " -0.02591581828892231,\n",
              " 0.015769558027386665,\n",
              " -0.09645098447799683,\n",
              " 0.05003301054239273,\n",
              " 0.04635874181985855,\n",
              " -0.020323894917964935,\n",
              " -0.03281765431165695,\n",
              " -0.020427625626325607,\n",
              " -0.021751996129751205,\n",
              " 0.015264852903783321,\n",
              " -0.12102898210287094,\n",
              " 0.062019191682338715,\n",
              " -0.044078510254621506,\n",
              " -0.041878826916217804,\n",
              " -0.07718702405691147,\n",
              " -0.04464314505457878,\n",
              " 0.03802918642759323,\n",
              " -0.012875773943960667,\n",
              " 0.06118123605847359,\n",
              " 0.020189624279737473,\n",
              " -0.08533575385808945,\n",
              " -0.040794286876916885,\n",
              " -0.0657784715294838,\n",
              " 0.028564296662807465,\n",
              " 0.057003263384103775,\n",
              " 0.03561411798000336,\n",
              " -0.06868698447942734,\n",
              " -0.03562813252210617,\n",
              " -0.0020883099641650915,\n",
              " 0.11379002779722214,\n",
              " -0.023593945428729057,\n",
              " -0.008224793709814548,\n",
              " -0.05450800806283951,\n",
              " -0.0262607391923666,\n",
              " 0.02136770449578762,\n",
              " 0.04776725918054581,\n",
              " -0.03840892016887665,\n",
              " 0.02500101923942566,\n",
              " 0.02654586173593998,\n",
              " 0.05460624396800995,\n",
              " 0.004635571967810392,\n",
              " -0.0018330790335312486,\n",
              " 0.010012599639594555,\n",
              " -0.07551389932632446,\n",
              " 0.028319645673036575,\n",
              " -0.027768412604928017,\n",
              " -0.04894675314426422,\n",
              " 0.11859888583421707,\n",
              " -0.03392782807350159,\n",
              " -0.02792619913816452,\n",
              " -0.0205265823751688,\n",
              " 0.014518492855131626,\n",
              " 0.07288710027933121,\n",
              " 0.00593487499281764,\n",
              " 0.03451742231845856,\n",
              " -0.019085265696048737,\n",
              " 0.0451163724064827,\n",
              " 0.05641733855009079,\n",
              " -6.032703225855585e-08,\n",
              " -0.005633982829749584,\n",
              " -0.04813239723443985,\n",
              " 0.04618177190423012,\n",
              " 0.05739743635058403,\n",
              " -0.0686928927898407,\n",
              " 0.01248318050056696,\n",
              " 0.00762645248323679,\n",
              " 0.016787081956863403,\n",
              " 0.008946143090724945,\n",
              " 0.05601455643773079,\n",
              " 0.028519894927740097,\n",
              " 0.01992621086537838,\n",
              " 0.019113896414637566,\n",
              " 0.00606929324567318,\n",
              " -0.034047238528728485,\n",
              " 0.051172517240047455,\n",
              " -0.15238559246063232,\n",
              " -0.007578225340694189,\n",
              " -0.04115162044763565,\n",
              " -0.05520743876695633,\n",
              " -0.04489285498857498,\n",
              " -0.0597156286239624,\n",
              " 0.06688936054706573,\n",
              " 0.0026603236328810453,\n",
              " -0.0037329967599362135,\n",
              " -0.05763792246580124,\n",
              " -0.08557309955358505,\n",
              " -0.0034220837987959385,\n",
              " -0.0082828588783741,\n",
              " 0.034779470413923264,\n",
              " -0.08423954248428345,\n",
              " 0.016355644911527634,\n",
              " 0.011327438987791538,\n",
              " 0.020163116976618767,\n",
              " -0.0014744747895747423,\n",
              " 0.02152111940085888,\n",
              " 0.13828185200691223,\n",
              " -0.030973363667726517,\n",
              " 0.00704185338690877,\n",
              " 0.11176952719688416,\n",
              " 0.09137175232172012,\n",
              " -0.023770134896039963,\n",
              " -0.0391860194504261,\n",
              " 0.031423162668943405,\n",
              " 0.02616022527217865,\n",
              " -0.05991857871413231,\n",
              " -0.07330645620822906,\n",
              " 0.013042453676462173,\n",
              " -0.08862025290727615,\n",
              " 0.09578534960746765,\n",
              " 0.04719984903931618,\n",
              " -0.06183016300201416,\n",
              " 0.011729328893125057,\n",
              " 0.07216701656579971,\n",
              " -0.01327486615628004,\n",
              " 0.019478730857372284,\n",
              " -0.09132666140794754,\n",
              " -0.03135988488793373,\n",
              " 0.06974489241838455,\n",
              " 0.0324055440723896,\n",
              " -0.033285953104496,\n",
              " -0.1182391494512558,\n",
              " 0.008446992374956608,\n",
              " 0.029700051993131638]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_vectors[0]['metadata']['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "c3n27BMsln6J",
        "outputId": "80cafad5-61e1-42f6-ebc0-a08cc83ca427"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Smart Health 31 (2024) 100445\\nAvailable online 18 January 2024\\n2352-6483/© 2024 Elsevier Inc. All rights reserved.\\nContents lists available at ScienceDirect\\nSmart Health\\njournal homepage: www.elsevier.com/locate/smhl\\nDesign and technical evaluation of an AMBU-BAG based low-cost\\nventilator-AARMED\\nMohit Kumar a,1, Ravinder Kumar b,∗,1, Vishal Kumar c, Amanpreet Chander a,\\nAbhinav Airan d, Rajesh Arya e, Gurpreet Singh Wander e, Ashish Kumar Sahani a\\na Department of Biomedical Engineering, Indian Institute of Technology, Ropar, India\\nb Department of Bioengineering, University of Pittsburgh, USA\\nc University of Notre Dame, USA\\nd Magnimus Systems, Bhopal, India\\ne Dayanand Medical College and Hospital (DMC&H), Ludhiana, India\\nA R T I C L E\\nI N F O\\nKeywords:\\nAARMED\\nAmbu-bag\\nVentilator\\nCovid-19\\nA B S T R A C T\\nThe COVID-19 pandemic has caused a significant strain on the healthcare system worldwide,\\nresulting in an acute shortage of ventilators. Conventional ventilators are costly, and producti'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_vectors[0]['metadata']['source']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Y_FI4DEplz-U",
        "outputId": "a5000713-92b0-4cef-a579-a344fcae3556"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'PDFStore/AARMED_Ventilator_Paper (1).pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Initializing the Hugging Face Pipeline**\n",
        "The first thing we need to do is initialize a text-generation pipeline with Hugging Face transformers. The Pipeline requires three things that we must initialize first, those are:\n",
        "\n",
        "*   A LLM, in this case it will be meta-llama/Llama-2-13b-chat-hf.\n",
        "\n",
        "*   The respective tokenizer for the model.\n",
        "\n",
        "We'll explain these as we get to them, let's begin with our model.\n",
        "\n",
        "We initialize the model and move it to our CUDA-enabled GPU. Using Colab this can take 5-10 minutes to download and initialize the model."
      ],
      "metadata": {
        "id": "8c5UPP1gZbDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import cuda, bfloat16\n",
        "import transformers\n",
        "from google.colab import userdata\n",
        "\n",
        "model_id = 'meta-llama/Llama-2-13b-chat-hf'\n",
        "\n",
        "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
        "\n",
        "# set quantization configuration to load large model with less GPU memory\n",
        "# this requires the `bitsandbytes` library\n",
        "bnb_config = transformers.BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type='nf4',\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=bfloat16\n",
        ")\n",
        "\n",
        "# begin initializing HF items, need auth token for these\n",
        "hf_auth = userdata.get('HuggingFaceKey')\n",
        "model_config = transformers.AutoConfig.from_pretrained(\n",
        "    model_id,\n",
        "    use_auth_token=hf_auth\n",
        ")\n",
        "\n",
        "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    trust_remote_code=True,\n",
        "    config=model_config,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map='auto',\n",
        "    use_auth_token=hf_auth\n",
        ")\n",
        "model.eval()\n",
        "print(f\"Model loaded on {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158,
          "referenced_widgets": [
            "6cdfad4d0e91407c93603691d26445be",
            "2e0e7a16deff407799b5e2e97f4b6d9f",
            "53f762fa2d62482198b2bc77c2debda8",
            "828ef186271b40bd81b183b1e62b2d24",
            "7deb0b28970945bd8f2c99f02fb52b0f",
            "dad41ab1f884490d949f24f26fd7b93d",
            "8a1666873b884a04b22ea9df28c106ac",
            "ad22b05949b445f6b62cebbca807686e",
            "45b8794eac404c4e9abf96b9a05b5b1e",
            "3593aeb4ad724034b6d3a6de90362afd",
            "24e823eb352a47d893f7db8bf3af2b0d"
          ]
        },
        "id": "GOtAY45dZYl_",
        "outputId": "6b725570-ecba-41cd-f07b-5da72b81cf94"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/configuration_auto.py:919: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:468: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6cdfad4d0e91407c93603691d26445be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded on cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pipeline requires a tokenizer which handles the translation of human readable plaintext to LLM readable token IDs. The Llama 2 13B models were trained using the Llama 2 13B tokenizer, which we initialize like so:"
      ],
      "metadata": {
        "id": "Zfr1k1Kz6jD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Load vectors from the pickle file\n",
        "with open('embeddings/vectors.pkl', 'rb') as f:\n",
        "    vectors = pickle.load(f)\n",
        "\n",
        "# Separate embeddings and metadata\n",
        "embeddings = np.array([v['embedding'] for v in vectors])\n",
        "metadata = [v['metadata'] for v in vectors]"
      ],
      "metadata": {
        "id": "hSSGjRYEnT02"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def retrieve(query_embedding, embeddings, metadata, top_k=5):\n",
        "    similarities = cosine_similarity([query_embedding], embeddings)[0]\n",
        "    indices = np.argsort(similarities)[-top_k:][::-1]\n",
        "    return [metadata[i] for i in indices], [similarities[i] for i in indices]"
      ],
      "metadata": {
        "id": "C-dIWLPyf3yt"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import textwrap\n",
        "\n",
        "# Example usage:\n",
        "query = \"What is the use of AARMED?\"\n",
        "\n",
        "# Generate query embedding\n",
        "query_embedding = embed_model.embed_documents([query])[0]\n",
        "retrieved_chunks, scores = retrieve(query_embedding, embeddings, metadata, top_k=3)\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(model_id, use_auth_token=hf_auth)\n",
        "\n",
        "# RAG Response\n",
        "# Combine retrieved chunks into a single context\n",
        "context = \"\\n\".join([chunk['text'] for chunk in retrieved_chunks])\n",
        "\n",
        "# Generate RAG response using the context\n",
        "rag_input_text = f\"Context: {context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
        "rag_inputs = tokenizer(rag_input_text, return_tensors=\"pt\").to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    rag_outputs = model.generate(**rag_inputs, max_length=2048, num_return_sequences=1)\n",
        "\n",
        "rag_response = tokenizer.decode(rag_outputs[0], skip_special_tokens=True)\n",
        "rag_helpful_answer = rag_response.split('Answer: ')[-1]\n",
        "\n",
        "# Wrap the text for RAG response\n",
        "rag_wrapped_answer = textwrap.fill(rag_helpful_answer, width=80)\n",
        "\n",
        "# Non-RAG Response\n",
        "# Generate non-RAG response without context\n",
        "non_rag_input_text = f\"Question: {query}\\nAnswer:\"\n",
        "non_rag_inputs = tokenizer(non_rag_input_text, return_tensors=\"pt\").to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    non_rag_outputs = model.generate(**non_rag_inputs, max_length=2048, num_return_sequences=1)\n",
        "\n",
        "non_rag_response = tokenizer.decode(non_rag_outputs[0], skip_special_tokens=True)\n",
        "non_rag_helpful_answer = non_rag_response.split('Answer: ')[-1]\n",
        "\n",
        "# Wrap the text for non-RAG response\n",
        "non_rag_wrapped_answer = textwrap.fill(non_rag_helpful_answer, width=80)\n",
        "\n",
        "# Print the results\n",
        "print(\"Question: \" + query)\n",
        "print(\"\\nRAG Answer: \" + rag_wrapped_answer)\n",
        "print(\"\\nNon-RAG Answer: \" + non_rag_wrapped_answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQAc8ZgBgZad",
        "outputId": "a9a56a48-688f-417a-f85e-a705b3617465"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py:769: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: What is the use of AARMED?\n",
            "\n",
            "RAG Answer: AARMED is a significant innovation in the field of respiratory care for COVID-19\n",
            "patients. It provides a reliable and effective solution for patients who do not\n",
            "have access to a mechanical ventilator, and it can help to reduce the risk of\n",
            "complications and death associated with COVID-19. Additionally, AARMED is a low-\n",
            "cost device, making it an affordable option for patients and healthcare systems.\n",
            "Overall, AARMED is a valuable resource for healthcare providers and patients\n",
            "during the COVID-19 pandemic.\n",
            "\n",
            "Non-RAG Answer: AARMED (Aeromedical Evacuation and Medical Evacuation) is a system used by the\n",
            "military to transport wounded or injured personnel from the battlefield to\n",
            "medical facilities for treatment. It is used to provide timely and effective\n",
            "medical care to those who are injured or become ill during military operations.\n",
            "The AARMED system includes a network of medical facilities, transportation\n",
            "assets, and communication systems that work together to ensure the safe and\n",
            "efficient transportation of patients. It is typically used in combat situations\n",
            "where medical care is not readily available or where the patient needs more\n",
            "advanced medical care than what is available on the battlefield.  The AARMED\n",
            "system is designed to provide a seamless and coordinated approach to medical\n",
            "evacuation, with a focus on rapid transportation and high-quality medical care.\n",
            "It is an essential component of military medicine and plays a critical role in\n",
            "ensuring the health and well-being of military personnel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buTxEPVWuUGO",
        "outputId": "04d56a66-7cf7-42ca-c33c-e3c3112d108c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.35.0-py2.py3-none-any.whl (8.6 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/8.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/8.6 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m7.7/8.6 MB\u001b[0m \u001b[31m112.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m115.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.25.2)\n",
            "Requirement already satisfied: packaging<25,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.0)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.0.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (16.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.11.0)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m110.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-4.0.1-py3-none-manylinux2014_x86_64.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
            "Installing collected packages: watchdog, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.43 pydeck-0.9.1 smmap-5.0.1 streamlit-1.35.0 watchdog-4.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import fitz  # PyMuPDF\n",
        "import os\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import torch\n",
        "import textwrap\n",
        "import numpy as np\n",
        "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
        "import transformers\n",
        "\n",
        "# Initialize embedding model\n",
        "embed_model_id = 'sentence-transformers/all-MiniLM-L6-v2'\n",
        "device = f'cuda:{torch.cuda.current_device()}' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "embed_model = HuggingFaceEmbeddings(\n",
        "    model_name=embed_model_id,\n",
        "    model_kwargs={'device': device},\n",
        "    encode_kwargs={'device': device, 'batch_size': 32}\n",
        ")\n",
        "\n",
        "# Load the model\n",
        "model_id = 'meta-llama/Llama-2-7b-chat-hf'\n",
        "bnb_config = transformers.BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type='nf4',\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "hf_auth = 'your_key_here'\n",
        "model_config = transformers.AutoConfig.from_pretrained(\n",
        "    model_id,\n",
        "    use_auth_token=hf_auth\n",
        ")\n",
        "\n",
        "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    trust_remote_code=True,\n",
        "    config=model_config,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map='auto',\n",
        "    use_auth_token=hf_auth\n",
        ")\n",
        "model.eval()\n",
        "\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(model_id, use_auth_token=hf_auth)\n",
        "\n",
        "# Helper functions\n",
        "def read_pdf(file):\n",
        "    doc = fitz.open(stream=file.read(), filetype=\"pdf\")\n",
        "    text = \"\"\n",
        "    for page_num in range(len(doc)):\n",
        "        page = doc.load_page(page_num)\n",
        "        text += page.get_text()\n",
        "    return text\n",
        "\n",
        "def chunk_text(text, chunk_size=1000):\n",
        "    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
        "\n",
        "def process_pdf(file):\n",
        "    text = read_pdf(file)\n",
        "    chunks = chunk_text(text)\n",
        "    data = [{'source': file.name, 'chunk_id': idx, 'chunk': chunk} for idx, chunk in enumerate(chunks)]\n",
        "    return pd.DataFrame(data)\n",
        "\n",
        "def generate_embeddings(data_df):\n",
        "    all_vectors = []\n",
        "    batch_size = 32\n",
        "\n",
        "    for i in tqdm(range(0, len(data_df), batch_size)):\n",
        "        i_end = min(len(data_df), i + batch_size)\n",
        "        batch = data_df.iloc[i:i_end]\n",
        "        ids = [f\"{x['source']}-{x['chunk_id']}\" for _, x in batch.iterrows()]\n",
        "        texts = [x['chunk'] for _, x in batch.iterrows()]\n",
        "        embeds = embed_model.embed_documents(texts)\n",
        "\n",
        "        metadata = [{'text': x['chunk'], 'source': x['source']} for _, x in batch.iterrows()]\n",
        "\n",
        "        for idx, embed, meta in zip(ids, embeds, metadata):\n",
        "            vector_data = {'id': idx, 'embedding': embed, 'metadata': meta}\n",
        "            all_vectors.append(vector_data)\n",
        "\n",
        "    return all_vectors\n",
        "\n",
        "def retrieve(query_embedding, embeddings, metadata, top_k=5):\n",
        "    similarities = cosine_similarity([query_embedding], embeddings)[0]\n",
        "    indices = np.argsort(similarities)[-top_k:][::-1]\n",
        "    return [metadata[i] for i in indices], [similarities[i] for i in indices]\n",
        "\n",
        "def generate_response(query, context=None):\n",
        "    input_text = f\"Context: {context}\\n\\nQuestion: {query}\\nAnswer:\" if context else f\"Question: {query}\\nAnswer:\"\n",
        "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(**inputs, max_length=2048, num_return_sequences=1)\n",
        "\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response.split('Answer: ')[-1]\n",
        "\n",
        "# Streamlit app\n",
        "st.title(\"PDF QA System\")\n",
        "\n",
        "if 'vectors' not in st.session_state:\n",
        "    st.session_state.vectors = None\n",
        "\n",
        "uploaded_file = st.file_uploader(\"Upload a PDF file\", type=[\"pdf\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    with st.spinner(\"Processing PDF...\"):\n",
        "        data_df = process_pdf(uploaded_file)\n",
        "        st.session_state.vectors = generate_embeddings(data_df)\n",
        "\n",
        "    st.success(\"PDF processed and vectors generated.\")\n",
        "\n",
        "    query = st.text_input(\"Enter your question:\")\n",
        "\n",
        "    if query and st.session_state.vectors is not None:\n",
        "        embeddings = np.array([v['embedding'] for v in st.session_state.vectors])\n",
        "        metadata = [v['metadata'] for v in st.session_state.vectors]\n",
        "\n",
        "        query_embedding = embed_model.embed_documents([query])[0]\n",
        "        retrieved_chunks, _ = retrieve(query_embedding, embeddings, metadata, top_k=3)\n",
        "        context = \"\\n\".join([chunk['text'] for chunk in retrieved_chunks])\n",
        "\n",
        "        rag_response = generate_response(query, context)\n",
        "        non_rag_response = generate_response(query)\n",
        "\n",
        "        st.write(\"### Question:\")\n",
        "        st.write(query)\n",
        "        st.write(\"### RAG Answer:\")\n",
        "        st.write(rag_response)\n",
        "        st.write(\"### Non-RAG Answer:\")\n",
        "        st.write(non_rag_response)\n",
        "\n",
        "        if st.button(\"Ask another question\"):\n",
        "            st.experimental_rerun()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jicivcMij5e",
        "outputId": "69ebe243-469e-4c54-f3d3-e6941d2ca877"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check and kill any existing process on port 8501\n",
        "!fuser -k 8501/tcp\n",
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mINs5G23uZr2",
        "outputId": "00e1124b-f353-47c1-db29-8662b06f512c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.17.0.2:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.150.213.201:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 1.487s\n",
            "your url is: https://every-pumas-suffer.loca.lt\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing HuggingFaceEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.embeddings import HuggingFaceEmbeddings\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.embeddings import HuggingFaceEmbeddings\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here https://python.langchain.com/v0.2/docs/versions/v0_2/ \n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
            "  warn_deprecated(\n",
            "2024-06-15 12:30:49.070872: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-06-15 12:30:49.133606: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-06-15 12:30:49.133655: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-06-15 12:30:49.136020: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-06-15 12:30:49.146601: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-06-15 12:30:50.200290: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Unused kwargs: ['bnb_8bit_quant_type', 'bnb_8bit_use_double_quant', 'bnb_8bit_compute_dtype']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/configuration_auto.py:919: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:468: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n",
            "Loading checkpoint shards: 100% 2/2 [00:04<00:00,  2.35s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py:769: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing HuggingFaceEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.embeddings import HuggingFaceEmbeddings\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.embeddings import HuggingFaceEmbeddings\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here https://python.langchain.com/v0.2/docs/versions/v0_2/ \n",
            "  warn_deprecated(\n",
            "Unused kwargs: ['bnb_8bit_quant_type', 'bnb_8bit_use_double_quant', 'bnb_8bit_compute_dtype']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
            "Loading checkpoint shards: 100% 2/2 [00:04<00:00,  2.36s/it]\n",
            "100% 2/2 [00:00<00:00,  2.79it/s]\n",
            "Unused kwargs: ['bnb_8bit_quant_type', 'bnb_8bit_use_double_quant', 'bnb_8bit_compute_dtype']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
            "Loading checkpoint shards: 100% 2/2 [00:04<00:00,  2.43s/it]\n",
            "Unused kwargs: ['bnb_8bit_quant_type', 'bnb_8bit_use_double_quant', 'bnb_8bit_compute_dtype']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
            "Loading checkpoint shards: 100% 2/2 [00:04<00:00,  2.44s/it]\n",
            "100% 2/2 [00:00<00:00, 27.23it/s]\n",
            "Unused kwargs: ['bnb_8bit_quant_type', 'bnb_8bit_use_double_quant', 'bnb_8bit_compute_dtype']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
            "Loading checkpoint shards: 100% 2/2 [00:04<00:00,  2.45s/it]\n",
            "100% 2/2 [00:00<00:00, 26.81it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/langchain/_api/module_import.py:92: LangChainDeprecationWarning: Importing HuggingFaceEmbeddings from langchain.embeddings is deprecated. Please replace deprecated imports:\n",
            "\n",
            ">> from langchain.embeddings import HuggingFaceEmbeddings\n",
            "\n",
            "with new imports of:\n",
            "\n",
            ">> from langchain_community.embeddings import HuggingFaceEmbeddings\n",
            "You can use the langchain cli to **automatically** upgrade many imports. Please see documentation here https://python.langchain.com/v0.2/docs/versions/v0_2/ \n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Unused kwargs: ['bnb_8bit_quant_type', 'bnb_8bit_use_double_quant', 'bnb_8bit_compute_dtype']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/configuration_auto.py:919: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:468: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
            "  warnings.warn(\n",
            "2024-06-15 12:36:59.940 Uncaught app exception\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/streamlit/runtime/scriptrunner/script_runner.py\", line 600, in _run_script\n",
            "    exec(code, module.__dict__)\n",
            "  File \"/content/app.py\", line 39, in <module>\n",
            "    model = transformers.AutoModelForCausalLM.from_pretrained(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\", line 563, in from_pretrained\n",
            "    return model_class.from_pretrained(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\", line 3703, in from_pretrained\n",
            "    hf_quantizer.validate_environment(device_map=device_map)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/quantizers/quantizer_bnb_8bit.py\", line 86, in validate_environment\n",
            "    raise ValueError(\n",
            "ValueError: Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit the quantized model. If you want to dispatch the model on the CPU or the disk while keeping these modules in 32-bit, you need to set `load_in_8bit_fp32_cpu_offload=True` and pass a custom `device_map` to `from_pretrained`. Check https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu for more details. \n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H8AQDIq4u5Xb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
